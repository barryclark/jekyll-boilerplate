---	
layout: post	
title: AICVS 2.0 - Learning NLP - the Fun way by Manpreet Budhraja
---

AICVS hosted its Webinar Series AICVS 2.0 with the third session on 27th March 2021 on Learning NLP, conducted by Manpreet Budhraja. Manpreet is a NLP practitioner and currently works as a data engineer.  In this session, Manpreet explained the basics of NLP,  real world examples and hands-on coding experience. 


Manpreet started with explaining some basic terms commonly used in NLP. A word is a basic atomic unit of meaning. A single word in itself does not hold any meaning but the words around it give it a meaning. Manpreet then introduced the Max Match Algorithm. 
Corpus ia collection of text. This algorithm matches a word letter by letter with the corpus. When a sequence of letters matches, it is interpreted as a word. For example in speech recognition where there is no explicit word boundary information given within a continuous speech utterance.  The minimum edit distance between two strings is defined as the minimum number of editing operations ( like insertion, deletion, substitution) needed to transform one string to another. It is used in automatic spelling correction, in bioinformatics etc


Python is the preferred language to train NLP models and NLTK is the most used library to preprocess the data. **Tokenization** is the act of breaking up a sequence of strings into pieces such as words, symbols and other elements called tokens. The text is tokenized using the sentence_tokenizer function of nltk. It divides the sentence based on the period in the sentence. You may also tokenize using punctuation marks such as commas. Next remove stopwords from the text. These are the commonly used words such as ‘a’ ‘an’ ‘the’. 
Next, she implemented the minimum edit <ins>distance between two random words</ins>. A python library is available for this. 


Parts of Speech are required to understand what type of grammatical structure the words represent. There are two types of words, content words and function words. The content words are generally nouns, adjectives, verbs and adverbs. The function words are generally pronouns, prepositions, coordinating conjunctions, interjections, determiners. Manpreet used the nltk library for finding the pos tags of the words. 


Regular Expressions are used for generating passwords, validation of email etc. Regular expressions are patterns used to match character combinations in strings. This can be implemented using the re library in python. Manpreet implemented this for finding ‘the’, ‘The’, ‘whitespaces’,  etc in a text data. 
**Morphology** is the study of the way words are built up from smaller meaning units called <ins>MORPHEMES</ins>, Two broad classes are:

1. stems- root word 

2. affixes-(s,es,ing) additional meaning


Text segmentation is the process of dividing written text into meaningful units, such as words, sentences or topics. This is used in information retrieval, sentiment analysis, and document clustering. 

Stemming and lemmatization are two important preprocessing techniques. There are two types of stemming

**Porter stemmer**: it doesn't often generate stems that are actual english words and it is known for its simplicity and speed

**lancaster stemmer**: it is an iterative algorithm where each rule specifies either a deletion or replacement of an ending. It is simple but may lead to over-stemming. 

Manpreet demonstrated how stemming can create noise in the data and thus the need for lemmatization arises. 


_Zipf’s law_ is a discrete probability distribution that tells you the probability of encountering a word in a given corpus. The input is the rank of the word in terms of its total frequency. 
Language modeling is predicting the next word based on the previous words. This is widely used in google search, gmail, and messaging. Models that assign probabilities to sequences of words are called Language Models. The assumption that the probability of a word depends only on the previous word is called a <ins>Markov Assumption</ins>.  Unigrams, Bigrams, Trigrams are used to find frequency of words. 
Manpreet advises to take datasets on kaggle and start working on them. She also suggests some projects for beginners such as text mining, sentiment analysis using BERT, Transformers, LSTMs, RNN, question answer generation, machine translation etc. 

_Link to the video:_  

[![Learning NLP - the Fun way](http://img.youtube.com/vi/9rIS6fyTbpI/0.jpg)](https://www.youtube.com/watch?v=9rIS6fyTbpI "Learning NLP - the Fun way")
